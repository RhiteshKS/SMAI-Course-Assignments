
Description:
I used an iterative process to get to my current solution of using a DeiT(Data Efficient Image Transformer) which gave me the best performance on the 52% test dataset available.
I had first tried simple cnn with 2 convolution layers, max pooling and ReLu as the activation function and got a score of nearly 8.65, after that i used an architecture with greater number of convolution layers and the performance increased mildly.
I went on with pretrained models for trying out transfer learning and tried out various models with variable results. I tried vgg16, vgg19, Inception, Xception models and did get some sort of increased performance. Then I tried vision transformers and got very good results. I stuck with it and just increased epochs from 10 to 20 to 30. Got perfomance increase from 10 to 20 and very little from 20 to 30, owing to the model overfitting. I then tried a variation of vision transformer, the  DeiT, which is a data efficient image transformer with distillation through attention. It is more efficiently trained than the ViT and takes far less data and compute to run. So I used this with 15 epochs and got the best results. I also tried BeiT(Bert Pretraining of Image Transformers) which outperforms DeiT and ViT in image classification tasks but for this task, it didnt show good results. 

Later I tried ensemble method called Model Averaging which takes more than one model, trains them separately and does a simple arithmetic mean of their results to get the final output. I used two of my submissions, 8 and 11 which uses DeiT trained over 15 epochs and the other one, DeiT trained over 25 epochs with data augmentation. And got better results.
 Then I took its output file and used a 3rd model, DeiT 20 epochs and again did model averaging to get my final result.
